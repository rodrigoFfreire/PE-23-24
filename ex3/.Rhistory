# Exact
p_exact <- 1 - pgamma(time, ns, 1/a)
diff_abs <- abs(prop_over_limit - p_exact)
diff_abs * 100
prop_over_limit
p_exact
set.seed(1948)
a <- 4
ns <- 30
time <- 90
# Simulated
samples <- matrix(data = rexp(n = 1000 * ns, rate = 1/a), nrow = 1000, ncol = 30)
Ys <- rowSums(samples)
p_simulated <- mean(Ys > time)
# Exact
p_exact <- 1 - pgamma(time, ns, 1/a)
diff_abs <- abs(p_simulated - p_exact)
diff_abs * 100
p_simulated
p_exact
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(p - direct_p) * 100
diff_abs
set.seed(1950)
n <- 23
r <- 300
m <- 170
l <- -1.5
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(p - direct_p) * 100
diff_abs
l <- 1.5
set.seed(1950)
n <- 23
r <- 300
m <- 170
l <- 1.5
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(p - direct_p) * 100
diff_abs
1 - diff_abs
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(p - direct_p) * 100
diff_abs
set.seed(1950)
n <- 23
r <- 300
m <- 170
l <- 1.5
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(p - direct_p) * 100
diff_abs
set.seed(1950)
n <- 23
r <- 300
m <- 170
l <- 1.5
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(p - direct_p) * 100
diff_abs
p
set.seed(1950)
n <- 23
r <- 300
m <- 170
l <- 1.5
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
set.seed(1948)
a <- 4
ns <- 30
time <- 90
# Simulated
samples <- matrix(data = rexp(n = 1000 * ns, rate = 1/a), nrow = 1000, ncol = 30)
Ys <- rowSums(samples)
p_simulated <- mean(Ys > time)
# Exact
p_exact <- 1 - pgamma(time, ns, 1/a)
diff_abs <- abs(p_simulated - p_exact)
diff_abs * 100
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
proportions
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
estimated_p
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
prportions
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
frequencias_observadas <- hist(observacoes, breaks = classes, plot = FALSE)$counts
F_X <- function(x, a, b) {
if (x < a) {
return(0)
} else if (x < (a + b) / 2) {
return(2 * (x - a)^2 / ((b - a) * (b - a)))
} else if (x < b) {
return(1 - 2 * (b - x)^2 / ((b - a) * (b - a)))
} else {
return(1)
}
}
a <- 4.5
b <- 13
k <- 6
observacoes <- c(6.52, 5.48, 7.01, 7.07, 9.76, 7.45, 10.11, 8.78, 8.53, 7.14, 8.56, 8.22, 8.11, 8.72, 9.89, 12.01, 9.14, 7.26, 11.05, 12.14, 8.44, 10.98, 6.95, 11.37, 8.65, 11.03, 10.55, 8.77, 10.04, 9.70, 9.43, 8.91, 10.79, 12.38, 7.41, 10.80, 8.40, 8.16, 9.22, 11.29, 8.54, 12.57, 8.53, 9.12, 8.53, 8.62, 12.03, 7.64, 11.13, 7.18, 8.16, 9.29, 6.89, 10.45, 11.20, 9.38, 8.79, 4.71, 9.35, 10.80, 10.90, 9.86, 9.50, 8.17, 11.19, 7.89, 8.72, 8.74, 8.87, 8.63, 9.28, 6.58, 10.74, 8.12, 6.92, 6.89, 5.19, 10.73, 10.38, 8.74, 8.96, 8.60, 4.92, 7.48, 8.96, 10.96, 8.08, 7.15, 8.82, 5.69, 8.09, 10.21, 5.80, 9.76, 11.90, 8.73, 7.10, 11.13, 5.07, 9.43, 8.04, 10.76, 7.95, 9.06, 9.39, 7.70, 5.92, 9.32, 10.53, 10.26, 6.31, 6.34, 5.36, 7.75, 7.74, 8.42, 10.76, 11.39, 8.42, 9.79, 9.45, 9.17, 7.91, 5.79, 5.70, 8.74, 10.33, 11.00, 6.17, 9.11, 9.57, 11.82, 10.35, 8.37, 6.66, 6.97, 9.66, 12.18, 10.80, 11.14)
classes <- seq(a, b, length.out = k + 1)
frequencias_observadas <- hist(observacoes, breaks = classes, plot = FALSE)$counts
probabilidades_teoricas <- diff(sapply(classes, F_X, a = a, b = b))
n <- length(observacoes)
frequencias_esperadas <- n * probabilidades_teoricas
resultado_teste <- chisq.test(frequencias_observadas, p = probabilidades_teoricas)
valor_p <- round(resultado_teste$p.value, 4)
valor_p
set.seed(2822)
n <- 100
m <- 5000
lambda_0 <- 2.90
lambda_1 <- 3.15
k <- 3.234
error1 <- 0
error2 <- 0
for (i in 1:m) {
# Amostra sob a hipótese nula
x0 <- rpois(n = n, lambda = lambda_0)
# Amostra sob a alternativa
x1 <- rpois(n = n, lambda = lambda_1)
if (mean(x0) > k) {
error1 <- error1 + 1
}
if (mean(x1) <= k) {
error2 <- error2 + 1
}
}
p_error1 = error1 / m
p_error2 = error2 / m
print(p_error2 / p_error1)
library(pracma)
set.seed(1592)
n <- 12
data <- c(31.8,31.7,35.2,37.1,31.7,36.1,36.3,33.2,34.3,37.5,30.4,34.6,32.4,31.7,30.2,34.3,35.6,34.9,38.9)
samples <- sample(data, n, replace = FALSE)
gamma <- 0.96
a <- qchisq((1 - gamma) / 2, df = n - 1)
b <- qchisq((1 + gamma) / 2, df = n - 1)
s2 <- var(samples)
lower_bound <- (n - 1) * s2 / b
upper_bound <- (n - 1) * s2 / a
F <- function(x) {
eq1 <- pchisq(x[2], df = n - 1) - pchisq(x[1], df = n - 1) - gamma
eq2 <- dchisq(x[2], df = n + 3) - dchisq(x[1], df = n + 3)
return(c(eq1, eq2))
}
# Resolver as equações para obter (c, d)
quantis <- fsolve(F, x0 = c(a,b))$x
c <- quantis[1]
d <- quantis[2]
# Calcular o novo intervalo de confiança para sigma^2
lower_bound_new <- (n - 1) * s2 / d
upper_bound_new <- (n - 1) * s2 / c
print(abs((upper_bound - lower_bound) - (upper_bound_new - lower_bound_new)))
library(stats4)
dados <- c(8.54,4.76,5.15,4.96,6.25,7.22,12.9,6.04,8.86,4.88,6.54,4.53,4.7,5.38,5.96,5.17,5.09,5.11)
a <- 4.5
logverossim <- function(theta) {
if (theta <= 0) {
return(Inf)
}
n <- length(dados)
log_likelihood <- n * log(theta) - theta * sum(log(dados / a))
return(-log_likelihood)
}
vero <- mle(logverossim, start = list(theta = 3.4))
theta_hat <- coef(vero)["theta"]
p <- 0.25
q_p_est <- a * (1 - p)^(-1 / theta_hat)
theta_true <- 3.4
q_p_true <- a * (1 - p)^(-1 / theta_true)
desvio_absoluto <- abs(q_p_est - q_p_true)
desvio_absoluto
set.seed(1948)
a <- 4
ns <- 30
time <- 90
# Simulated
samples <- matrix(data = rexp(n = 1000 * ns, rate = 1/a), nrow = 1000, ncol = 30)
Ys <- rowSums(samples)
p_simulated <- mean(Ys > time)
# Exact
p_exact <- 1 - pgamma(time, ns, 1/a)
diff_abs <- abs(p_simulated - p_exact)
diff_abs * 100
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
library(pracma)
set.seed(1592)
n <- 12
data <- c(31.8,31.7,35.2,37.1,31.7,36.1,36.3,33.2,34.3,37.5,30.4,34.6,32.4,31.7,30.2,34.3,35.6,34.9,38.9)
samples <- sample(data, n, replace = FALSE)
gamma <- 0.96
a <- qchisq((1 - gamma) / 2, df = n - 1)
b <- qchisq((1 + gamma) / 2, df = n - 1)
s2 <- var(samples)
lower_bound <- (n - 1) * s2 / b
upper_bound <- (n - 1) * s2 / a
F <- function(x) {
eq1 <- pchisq(x[2], df = n - 1) - pchisq(x[1], df = n - 1) - gamma
eq2 <- dchisq(x[2], df = n + 3) - dchisq(x[1], df = n + 3)
return(c(eq1, eq2))
}
# Resolver as equações para obter (c, d)
quantis <- fsolve(F, x0 = c(a,b))$x
c <- quantis[1]
d <- quantis[2]
# Calcular o novo intervalo de confiança para sigma^2
lower_bound_new <- (n - 1) * s2 / d
upper_bound_new <- (n - 1) * s2 / c
print(abs((upper_bound - lower_bound) - (upper_bound_new - lower_bound_new)))
library(stats4)
dados <- c(8.54,4.76,5.15,4.96,6.25,7.22,12.9,6.04,8.86,4.88,6.54,4.53,4.7,5.38,5.96,5.17,5.09,5.11)
a <- 4.5
logverossim <- function(theta) {
if (theta <= 0) {
return(Inf)
}
n <- length(dados)
log_likelihood <- n * log(theta) - theta * sum(log(dados / a))
return(-log_likelihood)
}
vero <- mle(logverossim, start = list(theta = 3.4))
theta_hat <- coef(vero)["theta"]
p <- 0.25
q_p_est <- a * (1 - p)^(-1 / theta_hat)
theta_true <- 3.4
q_p_true <- a * (1 - p)^(-1 / theta_true)
desvio_absoluto <- abs(q_p_est - q_p_true)
desvio_absoluto
set.seed(1948)
a <- 4
ns <- 30
time <- 90
# Simulated
samples <- matrix(data = rexp(n = 1000 * ns, rate = 1/a), nrow = 1000, ncol = 30)
Ys <- rowSums(samples)
p_simulated <- mean(Ys > time)
# Exact
p_exact <- 1 - pgamma(time, ns, 1/a)
diff_abs <- abs(p_simulated - p_exact)
diff_abs * 100
set.seed(2126)
n <- 4
r <- 150
m <- 130
l <- -0.9
samples <- matrix(NA, nrow = r, ncol = m)
for (i in 1:r) {
for (j in 1:m) {
z <- rnorm(n + 1)
samples[i, j] <- (sqrt(n) * z[1] / sqrt(sum(z[-1]^2)))
}
}
proportions <- apply(samples, 1, function(row) mean(row <= l))
estimated_p <- mean(proportions)
direct_p <- pt(l, df = n)
diff_abs <- abs(estimated_p - direct_p) * 100
diff_abs
set.seed(2255)
n_sims <- 150
beep_code <- 2
off_code <- 1
notoff <- 0
beeps <- 0
for (i in 1:n_sims) {
signals <- sample(1:10, 9, replace = TRUE, prob = (1:10)/55)
if (!(off_code) %in% signals) {
notoff <- notoff + 1
if (beep_code %in% signals) {
beeps <- beeps + 1
}
}
}
notoff_prob <- notoff / n_sims
beeps_prob <- beeps / n_sims
print(round(beeps_prob/notoff_prob,2))
set.seed(2255)
n_sims <- 150
beep_code <- 2
off_code <- 1
notoff <- 0
beeps <- 0
for (i in 1:n_sims) {
signals <- sample(1:10, 9, replace = TRUE, prob = (1:10)/55)
if (!(off_code) %in% signals) {
notoff <- notoff + 1
if (beep_code %in% signals) {
beeps <- beeps + 1
}
}
}
notoff_prob <- notoff / n_sims
beeps_prob <- beeps / n_sims
beeps_prob / notoff_prob
setwd("~/Desktop/IST/YEAR2/PE/PE-23-24/ex3")
library(ggplot2)
theme_set(theme_dark())
data <- readxl::read_excel("./electricity.xlsx")
product <- "Renewables"
min_year <- 2015
countries <- c("Italy", "Latvia", "IEA Total")
filtered_data <- subset(data, PRODUCT == product & YEAR >= min_year & COUNTRY %in% countries)
filtered_data$TIME <- as.Date(paste(filtered_data$TIME, "01"), format = "%B %Y %d")
filtered_data$share <- as.numeric(filtered_data$share)
filtered_data |>
ggplot(aes(x = TIME, y = share * 100, color = COUNTRY)) +
scale_y_continuous(limits = c(0, 100)) +
scale_x_date(date_breaks = "5 months", date_labels = "%B %Y") +
geom_line() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = paste("Monthly evolution of Renewable energies market share of Italy vs Latvia vs IEA Total"),
x = paste("Date"),
y = paste("Market Share Percentage (%)"))
filtered_data |>
ggplot(aes(x = TIME, y = share * 100, color = COUNTRY)) +
scale_y_continuous(limits = c(0, 100)) +
scale_x_date(date_breaks = "5 months", date_labels = "%B %Y") +
geom_line() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = paste("Monthly evolution of Renewable energies market share\nItaly vs Latvia vs IEA Total"),
x = paste("Date"),
y = paste("Market Share Percentage (%)"))
filtered_data |>
ggplot(aes(x = TIME, y = share * 100, color = COUNTRY)) +
scale_y_continuous(limits = c(0, 100)) +
scale_x_date(date_breaks = "5 months", date_labels = "%B %Y") +
geom_line() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = paste("Monthly market share evolution of renewable energies\nItaly vs Latvia vs IEA Total"),
x = paste("Date"),
y = paste("Market Share Percentage (%)"))
filtered_data |>
ggplot(aes(x = TIME, y = share * 100, color = COUNTRY)) +
scale_y_continuous(limits = c(0, 100)) +
scale_x_date(date_breaks = "5 months", date_labels = "%B %Y") +
geom_line() +
geom_point() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = paste("Monthly market share evolution of renewable energies\nItaly vs Latvia vs IEA Total"),
x = paste("Date"),
y = paste("Market Share Percentage (%)"))
